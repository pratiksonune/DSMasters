{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rjQkMA_Ug2cP"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.basicConfig(filename=\"30MarInfo.log\", level=logging.INFO, format=\"%(asctime)s %(name)s %(message)s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPfUxTNWh-_D"
      },
      "source": [
        "# answer 1\n",
        "Elastic Net Regression is a linear regression technique that combines the features of Ridge Regression and Lasso Regression. It is designed to overcome the limitations of these two techniques and to provide a better approach for high-dimensional data analysis.\n",
        "\n",
        "In traditional linear regression, we try to find a linear relationship between the dependent variable and independent variables. However, when there are many independent variables, multicollinearity can become a problem. This means that some of the independent variables are highly correlated with each other, which can lead to overfitting and poor performance of the model.\n",
        "\n",
        "Ridge Regression addresses this problem by adding a penalty term to the cost function, which reduces the magnitude of the coefficients of the independent variables. Lasso Regression, on the other hand, uses a different penalty term that sets some of the coefficients to zero, which can help in feature selection.\n",
        "\n",
        "Elastic Net Regression combines these two penalty terms, allowing for a more flexible approach that can handle multicollinearity and feature selection simultaneously. The combination of the two penalty terms allows for a balance between Ridge and Lasso Regression, resulting in a model that can handle both large and small coefficients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3LT20GQiBcn"
      },
      "source": [
        "# answer 2\n",
        "Choosing the optimal values of the regularization parameters for Elastic Net Regression involves a process called hyperparameter tuning. This process involves trying different combinations of hyperparameters and selecting the set of hyperparameters that yields the best performance of the model on a validation set.\n",
        "\n",
        "There are different methods to perform hyperparameter tuning for Elastic Net Regression. One common method is to use cross-validation. The general steps are as follows:\n",
        "\n",
        "> Split the data into training, validation, and testing sets.\n",
        "\n",
        "> Define a range of values for the regularization parameters alpha (for L1 penalty) and l1_ratio (the ratio of L1 to L2 penalty) that we want to try.\n",
        "\n",
        "> Use the training set to fit a model with each combination of alpha and l1_ratio values.\n",
        "\n",
        "> Use the validation set to evaluate the performance of each model.\n",
        "\n",
        "> Select the hyperparameters that result in the best performance on the validation set.\n",
        "\n",
        "> Evaluate the performance of the selected model on the testing set to assess its generalization performance.\n",
        "\n",
        "We can use different performance metrics to evaluate the performance of the model on the validation set, such as mean squared error (MSE), root mean squared error (RMSE), or coefficient of determination (R^2).\n",
        "\n",
        ">> Some libraries, such as scikit-learn in Python, provide functions to perform hyperparameter tuning automatically, such as GridSearchCV or RandomizedSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2h59zGN2G5B",
        "outputId": "e3b0b2fb-d868-409b-ccaf-d2bbef470a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'alpha': 0.1, 'l1_ratio': 0.9}\n",
            "Best score:  0.9997780855832061\n",
            "R-squared score:  0.9998905343509098\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate sample data\n",
        "X, y = make_regression(n_samples=100, n_features=10, random_state=42)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Elastic Net model\n",
        "enet = ElasticNet()\n",
        "\n",
        "# Set hyperparameters to tune\n",
        "params = {'alpha': [0.1, 1, 10],\n",
        "          'l1_ratio': [0.1, 0.5, 0.9]}\n",
        "\n",
        "# Perform Grid Search CV to find best hyperparameters\n",
        "grid_search = GridSearchCV(enet, param_grid=params, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best hyperparameters and corresponding score\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", grid_search.best_score_)\n",
        "\n",
        "# Test the model with best hyperparameters on test data\n",
        "best_enet = grid_search.best_estimator_\n",
        "y_pred = best_enet.predict(X_test)\n",
        "\n",
        "# Print R-squared score\n",
        "print(\"R-squared score: \", best_enet.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUfDUq0_iEwL"
      },
      "source": [
        "# answer 3\n",
        "# Advantages of Elastic Net Regression:\n",
        "\n",
        "1. Handles multicollinearity: Elastic Net Regression can handle multicollinearity among the independent variables, which can often lead to unstable and unreliable regression coefficients in other linear regression models.\n",
        "2. Provides feature selection: Elastic Net Regression can perform variable selection by setting some coefficients to zero. This can be useful when dealing with high-dimensional data sets where only a subset of the independent variables are relevant to the dependent variable.\n",
        "3. Improves prediction accuracy: By combining the L1 and L2 regularization techniques, Elastic Net Regression can provide more accurate predictions than other linear regression models, especially when dealing with noisy data or data sets with many independent variables.\n",
        "4. Flexible: The elastic net algorithm can be applied to a wide range of linear regression problems and can handle different types of variables, such as continuous, categorical, and binary variables.\n",
        "# Disadvantages of Elastic Net Regression:\n",
        "\n",
        "1. May be computationally expensive: The process of finding the optimal values of the regularization parameters can be computationally expensive, especially when dealing with large data sets and complex models.\n",
        "2. Parameter tuning: The performance of Elastic Net Regression depends heavily on the choice of regularization parameters, and finding the optimal values can be challenging and time-consuming.\n",
        "3. Less interpretable: The coefficients of Elastic Net Regression may be more difficult to interpret than those of other linear regression models, such as linear regression or Ridge Regression.\n",
        "4. Less well-known: Elastic Net Regression is a relatively new technique, and it may not be as well-known or widely used as other linear regression models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlseMQ5jiE3P"
      },
      "source": [
        "# answer 4\n",
        "Elastic Net Regression can be used in various fields where linear regression is applied. Some common use cases for Elastic Net Regression are:\n",
        "\n",
        "1. Biomedical research: \n",
        "> Elastic Net Regression can be used in biomedical research to identify the relevant features or biomarkers that are associated with a particular disease or condition. It can also be used to predict clinical outcomes or to analyze gene expression data.\n",
        "\n",
        "2. Financial analysis:\n",
        "> Elastic Net Regression can be used in financial analysis to model the relationship between different financial variables, such as stock prices, interest rates, and economic indicators.\n",
        "\n",
        "3. Marketing research: \n",
        "> Elastic Net Regression can be used in marketing research to identify the factors that influence consumer behavior, such as demographic variables, product features, and pricing.\n",
        "\n",
        "4. Environmental studies:\n",
        "> Elastic Net Regression can be used in environmental studies to model the relationship between environmental variables, such as temperature, rainfall, and air quality, and their impact on ecological systems.\n",
        "\n",
        "5. Image analysis:\n",
        "> Elastic Net Regression can be used in image analysis to classify images or to identify the relevant features that are associated with a particular object or event.\n",
        "\n",
        "6. Social sciences:\n",
        "> Elastic Net Regression can be used in social sciences to analyze survey data and to model the relationship between different variables, such as income, education, and health outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba4X7Hf_iFA7"
      },
      "source": [
        "# answer 5\n",
        "The coefficients in Elastic Net Regression represent the change in the dependent variable (target) associated with a one-unit increase in the corresponding independent variable, while holding all other variables constant. The interpretation of the coefficients depends on the type of independent variable:\n",
        "\n",
        "1. Continuous variables: The coefficient for a continuous variable represents the change in the dependent variable associated with a one-unit increase in the independent variable, while holding all other variables constant.\n",
        "\n",
        "2. Categorical variables: The coefficient for a categorical variable represents the difference in the dependent variable between the reference group (usually the baseline or the most frequent category) and the other categories of the variable. For example, if we have a categorical variable for \"gender\" with two categories, male and female, and the reference group is male, then the coefficient for the female category represents the difference in the dependent variable between females and males, while holding all other variables constant.\n",
        "\n",
        "3. Interaction terms: If we have an interaction term between two variables, the coefficient for the interaction term represents the change in the dependent variable associated with a one-unit increase in the product of the two variables, while holding all other variables constant. The interpretation of the coefficients for the individual variables in the interaction term depends on the specific context and the values of the other variables in the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjLTzXIoiFJk"
      },
      "source": [
        "# answer 6\n",
        "Handling missing values is an important step in any data analysis or modeling task, including Elastic Net Regression. There are several approaches to handling missing values in Elastic Net Regression:\n",
        "\n",
        "1. Complete case analysis: This approach involves removing all observations that have missing values in any of the variables used in the model. While this approach is simple and easy to implement, it can lead to loss of information and biased results if the missing data are not missing completely at random (MCAR).\n",
        "\n",
        "2. Imputation: This approach involves replacing the missing values with estimated values based on the observed values in the data set. There are several methods for imputing missing values, including mean imputation, median imputation, mode imputation, and regression imputation. Regression imputation involves using a regression model to predict the missing values based on the other variables in the data set. However, this approach can also lead to biased results if the missing data are not MCAR.\n",
        "\n",
        "3. Advanced imputation techniques: There are several advanced imputation techniques that can be used to handle missing values in Elastic Net Regression, such as multiple imputation, which involves creating multiple imputed data sets and running the Elastic Net Regression model on each of them, and imputation using machine learning algorithms such as K-nearest neighbors or decision trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL3P0dEm2G5L",
        "outputId": "bd74ca21-7ca2-42e9-f040-0612c9dac9f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha:  0.0015970391288520694\n",
            "Best l1_ratio:  0.5\n",
            "MAE score: 0.53\n",
            "MSE score: 0.55\n",
            "RMSE score : 0.74\n",
            "R2 score : 0.5770\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load California Housing dataset\n",
        "california_housing = fetch_california_housing(as_frame=True)\n",
        "X, y = california_housing.data, california_housing.target\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Impute missing values using mean imputation\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "# Use ElasticNetCV model for hyperparameter tuning\n",
        "model = ElasticNetCV(cv=5)\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate model on test set\n",
        "mse = mean_squared_error(y_test, y_test_pred)\n",
        "mae = mean_absolute_error(y_test, y_test_pred)\n",
        "r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"Best alpha: \", model.alpha_)\n",
        "print(\"Best l1_ratio: \", model.l1_ratio_)\n",
        "print(f\"MAE score: {mae:.2f}\")\n",
        "print(f\"MSE score: {mse:.2f}\")\n",
        "print(f\"RMSE score : {mse**0.5:.2f}\")\n",
        "print(f\"R2 score : {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uzk8iAC3iFTL"
      },
      "source": [
        "# answer 7\n",
        "Elastic Net Regression can be used for feature selection by identifying the most important variables that are associated with the target variable. The Elastic Net Regression model includes a regularization term that penalizes the magnitude of the coefficients, which encourages the model to select only the most important variables and discard the irrelevant ones. There are several approaches to using Elastic Net Regression for feature selection:\n",
        "\n",
        "> L1 regularization: Setting the l1_ratio parameter in the Elastic Net Regression model to 1 will result in L1 regularization, also known as Lasso regression. L1 regularization is a powerful method for feature selection because it shrinks the coefficients of irrelevant variables to zero, effectively removing them from the model.\n",
        "\n",
        "> L2 regularization: Setting the l1_ratio parameter in the Elastic Net Regression model to 0 will result in L2 regularization, also known as Ridge regression. L2 regularization can also be used for feature selection, but it does not shrink the coefficients to zero, which means that all variables are retained in the model, albeit with smaller coefficients.\n",
        "\n",
        "> Cross-validation: Cross-validation can be used to estimate the performance of the Elastic Net Regression model and select the optimal values of the regularization parameters (alpha and l1_ratio). By selecting the values of alpha and l1_ratio that result in the best cross-validation performance, we can obtain a model that is optimized for feature selection.\n",
        "\n",
        "> Coefficient thresholding: After fitting the Elastic Net Regression model, we can set a threshold for the magnitude of the coefficients and discard all variables with coefficients below the threshold. This approach is simple and easy to implement but may lead to suboptimal results if the threshold is not chosen carefully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ876IAn2G5N",
        "outputId": "2b3805e2-7c52-44aa-f2e1-036483267cb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 score: 0.5148375114202305\n",
            "Selected features: [('MedInc', 0.7124071084662037), ('HouseAge', 0.137194210466035), ('Latitude', -0.1758866518884966), ('Longitude', -0.13334284564464793)]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "california = fetch_california_housing()\n",
        "X, y = california.data, california.target\n",
        "\n",
        "# Scale data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Elastic Net model with cross-validation to choose hyperparameters\n",
        "model = ElasticNetCV(l1_ratio=0.5, alphas=[0.1, 0.5, 1.0],cv=5)\n",
        "\n",
        "# Fit model to training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model on testing data\n",
        "score = model.score(X_test, y_test)\n",
        "print(\"R^2 score:\", score)\n",
        "\n",
        "# Get coefficients and feature names\n",
        "coef = model.coef_\n",
        "feature_names = california.feature_names\n",
        "\n",
        "# Print selected features and their coefficients\n",
        "selected_features = []\n",
        "for i in range(len(feature_names)):\n",
        "    if coef[i] != 0:\n",
        "        selected_features.append((feature_names[i], coef[i]))\n",
        "print(\"Selected features:\", selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYopQebhiFbW"
      },
      "source": [
        "# answer 8\n",
        "Pickle is a Python module that is used to serialize and deserialize Python objects, including trained machine learning models. \n",
        "\n",
        "> To pickle a trained Elastic Net Regression model:\n",
        "```\n",
        "import pickle\n",
        "from sklearn.linear_model import ElasticNet\n",
        "// train Elastic Net Regression model\n",
        "en = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "en.fit(X_train, y_train)\n",
        "// save model to disk\n",
        "with open('en_model.pkl', 'wb') as f:\n",
        "    pickle.dump(en, f)\n",
        "```\n",
        "\n",
        "> To unpickle a trained Elastic Net Regression model:\n",
        "```\n",
        "import pickle\n",
        "// load model from disk\n",
        "with open('en_model.pkl', 'rb') as f:\n",
        "    en = pickle.load(f)\n",
        "// use model to make predictions\n",
        "y_pred = en.predict(X_test)\n",
        "```\n",
        "\n",
        "In the above example, we first import the pickle module and the ElasticNet class from the sklearn.linear_model module. We then train an Elastic Net Regression model on some training data (X_train and y_train) and save it to disk using the pickle.dump() method. The wb argument specifies that we want to write the model to a binary file.\n",
        "\n",
        "To unpickle the model, we load it from disk using the pickle.load() method and use it to make predictions on some test data (X_test). The rb argument specifies that we want to read the model from a binary file.\n",
        "\n",
        "It's important to note that when unpickling a model, it's crucial to ensure that the same version of the sklearn library is installed as when the model was pickled. This is because the implementation of the Elastic Net Regression model may change between different versions of the library, which could lead to errors when unpickling the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwY5NGojiFmj"
      },
      "source": [
        "# answer 9\n",
        "The purpose of pickling a model in machine learning is to save a trained model to disk so that it can be reused later without having to retrain the model from scratch.\n",
        "\n",
        "When we train a machine learning model, we typically fit the model to a set of training data and then evaluate its performance on a separate set of test data. Once we have found a model that performs well on the test data, we may want to save the model so that we can use it to make predictions on new, unseen data without having to retrain the model every time.\n",
        "\n",
        "Pickling a trained model allows us to save the model's parameters to disk in a binary format, which can be loaded and used later to make predictions on new data. This can be particularly useful in applications where real-time predictions are required or when working with large datasets that require significant computation time to train.\n",
        "\n",
        "In addition, pickling a model allows us to share the model with others, such as colleagues or clients, who may not have access to the original training data or may not have the time or resources to train the model themselves.\n",
        "\n",
        "Overall, pickling a model is a useful technique for saving and reusing trained machine learning models, which can save time and resources in the development and deployment of machine learning applications."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}